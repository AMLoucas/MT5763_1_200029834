---
title: "MT5761 Individual Project"
output: html_document
author: 200029834
---
```{r setup, include=FALSE}
## Global chunk variables to se for all script.
knitr::opts_chunk$set(echo = TRUE,
                      eval = TRUE,
                      message = FALSE)
```

```{r, include=FALSE}
## Functions that will be used in the program miltiple times.
## For deleting unwanted columns.
deleteColumn <- function(dataFrame, columns){
  for (col in columns){
    dataFrame <- dataFrame %>%
      select(-col) ## '-' notation means to select all except the given column.
  }
  return(dataFrame)
}

## For converting a column to class Date.
## formatDate is used because for the conversion you need to specify in what format your date is in.
## Using functions that tidyverse and lubridate offer.
convertDate <- function(dataFrame, formatDate){
  dataFrame <- dataFrame %>%
    mutate(Date = (as_date(parse_date_time(Date,formatDate)))) 
  return(dataFrame)
}

## For Creating new Column FullDate holding Date and Hour of the day.
## as.integer(format(Date, format="%Y") -> this command is needed to extract the correct number/attribute from column Date. "%Y" tells the function to extract the year. as.integer() converts the character into an integer becasue field year expects as integer number. All work the same [month, day, hour]
createFullDate <- function(dataFrame){
  dataFrame <- dataFrame %>%
  mutate(FullDate = make_datetime( year = as.integer(format(Date, format="%Y"))
                                  , month = as.integer(format(Date, format="%m"))
                                  ,day = as.integer(format(Date, format="%d"))
                                  , hour = Hour 
                                  ,min = 0
                                  , sec = 0 ))
  return(dataFrame)
  

  
}

```

 \ <!-- chnage line symbol -->
 
## INTRODUCTION :

<p>
The purpose of the individual project is to clean two data-sets which will later allow us to compare them and combine their data in a way where we will be able to obtain important information. In the project we are required to use version control system called 'git' and create a report using R Markdown.
</p>
<p>
During the process of the project we will be working with 2 specific data sets (CSV files.) 
  
  * BikeSeoul.csv
  * BikeWashingtonDC.csv
  
These two data sets contain the number of bikes rented at each hour in each of the continents/states. In the beginning the two given data sets are "messy"/not clean . In the project we will apply Data Wrangling to the data, resulting in having a "tidy"/clean data set. Once the files are in the correct format, we will create different plots to explore the relationships between rented bikes in  Washington, D.C., USA with Seoul, South Korea . We will also use the plots to examine if these numbers are determined by the weather conditions (Humidity, Temperature, Wind Speed). Once we visualize all these summaries, we will apply statistical analysis on the data to understand the relationship of the data even more and predict future outcomes. \
The given techniques will be applied on the two CSV files data:

  * Data Wrangling
  * Data Visualisation
  * Statistical modelling
  
</p>

## DATA WRANGLING :
```{r, echo=FALSE}
## Importing libraries needed to use specific functions commands.
library(lubridate)
library(tidyverse)
library(plotly)
```

### Seoul, South Korea Data File beginning state
```{r,}
seoul_Bikes <- read.csv("BikeSeoul.csv")
head(seoul_Bikes)
```

<p>
Above we can see the  beginning state of the file("BikeSeoul.csv"). We can notice that their are some issues with the Data Structure of the data set.
  
  * Column names are too long [Rented.Bike.Count, Solar.Radiation..MJ.m2., ...]
  * Unclear column names (too much notation that creates confusion) [Dew.point.temperature.C. ,]
  * Values are too long and take more time to code ['No Holiday']

These problems create clutter in the data and make it harder for us to understand it. In the first glimpse the data is difficult to read and extract estimates.
</p>
<br><br />

#### [TASK 1]
<p>
Our first task in our Data Wrangling is to remove all the rows that indicate a bike was not rented, after remove the column 'Functioning Day' which specifies this data. \
**Implemantation idea** \
Column 'Functioning Day' states if a bike was rented or not. We will have to filter through the rows and obtaining the records that have value "Yes" for attribute 'Functioning Day'. These are the records that a bike was rented. Once we have obtained these rows we can remove the column 'Functioning Day'.
</p>
```{r}
## Number of rows before removing unneeded records are:
nrow(seoul_Bikes)
seoul_Bikes <- seoul_Bikes %>%
  filter(Functioning.Day != "No") %>% ## Collect rows with value Yes in column Functioning.Day
  select(-Functioning.Day) ## Remove column Functioning.Day
## Number of rows after removing unneeded records are:
nrow(seoul_Bikes)
```
<br><br />

#### [TASK 2]
<p>
Our second task is to rename some column names to more appropriate ones. \
From our first glimpse of the table we can notice that some column names do not have appropriate names.

  * 'Rented.Bike.Count' to 'Count'
  * 'Temperature.C.' to 'Temperature'
  * 'Wind.speed..m.s.' to 'WindSpeed'
  * 'Seasons' to 'Season'
  * 'Humidity...' to 'Humidity'

**Implemantation idea** \
Using function rename() from tidyverse we can simply rename the column names to more appropriate ones.
</p>
```{r}
## Header Names before Renaming
names(seoul_Bikes)
seoul_Bikes <- seoul_Bikes %>%
  rename(Count = Rented.Bike.Count, ## Using function we are renaming the columns.
         Temperature = Temperature.C., 
         WindSpeed = Wind.speed..m.s., 
         Season = Seasons,
         Humidity = Humidity...)
## Header Names after Renaming
names(seoul_Bikes)
```
<br><br />

#### [TASK 3] 
<p>
Our third task is to convert column Date from type 'character' to type to 'Date'. \
**Implemantation idea** \
With the help of tidyverse function 'as_date()' we will change the type/class of the attribute.
</p>
```{r}
## Printing class of column Date before mutation.
class(seoul_Bikes$Date)

seoul_Bikes <- seoul_Bikes %>%
  convertDate("dmy")
## Printing class of column Date after mutation.
class(seoul_Bikes$Date)
```
<br><br />

#### [TASK 4]
<p>
Our fourth task is to add a new column with name 'FullDate' which will hold the Date and Hour of the day the bike was rented in format 'Y-M-D H:M:S' \
**Implemantation idea** \
With help of package lubridate we have a function called 'make_datetime' which does this action for us in the format asked.
</p>
```{r}
## Printing column names to show that FullDate does not exist.
names(seoul_Bikes)
## Calling a self-declared function to undertake this task.
seoul_Bikes <- seoul_Bikes %>%
  createFullDate()
## Printing column names to show creation of FullDate.
names(seoul_Bikes)
## Printing first 6 rows of FullDate to show the value is in correct format.
head(seoul_Bikes$FullDate)
```
<br><br />

#### [TASK 5] 
<p>
Our fifth task is to change Holiday values:
  
  * 'No Holiday' to 'No'
  * 'Holiday' to 'Yes'

Additionally to change the column type/class from 'character' to 'factor'. \
The reason we want to apply this change is to be able order our data to the bikes rented during a holiday and the onces rented when it was not a holiday. Factor type allows us to categorize data. \
**Implemantation idea** \
Using tidyverse function mutate in combination with ifelse conditional statement we will change the record values. Once the inputs have changed we create it to factors/category with the order :

  * Yes > No

</p>
```{r}
## Printing the 6 fist rows to show factor values before changing
head(seoul_Bikes$Holiday)
## Printing the class of Holiday to show its a 'character'
class(seoul_Bikes$Holiday)
seoul_Bikes <- seoul_Bikes %>%
  mutate(Holiday = ifelse(Holiday == "No Holiday", "No", "Yes")) %>% ## Changing values to Yes & No
  mutate(Holiday = factor(Holiday, levels = c("Yes", "No"))) ## Changing type to factor with seq order.
## Printing the 6 fist rows to show factor values have changed.
head(seoul_Bikes$Holiday)
## Printing the class of Holiday to show its a 'factor'
class(seoul_Bikes$Holiday)
```
<br><br />

#### [TASK 6] 
<p>
Our sixth task is to change the order of the Factor levels from column Season to the order:

  * Spring
  * Summer
  * Autumn
  * Winter

From highest to lowest. \
**Implemantation idea** \
Using tidyverse 'mutate()' function, we will convert the column to a factor and specify the order of the levels we want.
</p>
```{r}
## Printing class of the column to show its not a factor yet.
class(seoul_Bikes$Season)
seoul_Bikes <- seoul_Bikes %>%
  mutate(Season = factor(Season, levels = c("Spring", "Summer", "Autumn", "Winter")))
## Printing the 6 fist rows to show factor levels order after the change of class
head(seoul_Bikes$Season)
```
<br><br />

#### [TASK 7]
<p>
Our seventh and final task for cleaning the first data set is to removing unwanted columns : 

 * visibility
 * dew point temperature
 * solar radiation
 * rainfall
 * snowfall

**Implemantation idea** \
Using tidyverse function 'select' and the notation of the '-' we will remove the unwanted columns
</p>
```{r}
## Printing the column names of the table before removing unwanted data.
names(seoul_Bikes)
## Calling a self-declared function to undertaken given task.
seoul_Bikes <- seoul_Bikes %>%
  deleteColumn( c("Visibility..10m.",
                  "Solar.Radiation..MJ.m2.",
                  "Rainfall.mm.",
                  "Dew.point.temperature.C.",
                  "Snowfall..cm."))

## Printing column names and first 6 rows to show the end result of the data that has been cleaned.
names(seoul_Bikes)
```
<br><br />
<p>
After applying all these methods on the data set, we managed to clean the data and bring it to a 'tidy' state. Now the data is easier to read and manipulate in plotting and statistical analysis.
</p>
###### The result of Seoul, South Korea Data File after Data Wrangling is : 
```{r,}
head(seoul_Bikes)
```
<br><br />

### Washington DC, USA Data File beginning state
```{r,}
washington_Bikes <- read.csv("BikeWashingtonDC.csv")
head(washington_Bikes)
```
<p>
Above we can see the  beginning state of the file ("BikeWashingtonDC.csv"). We can notice that their are some issues with the Data Structure of the data set.
  
  * Column names are acronyms, users can distinguish differently [cnt, temp, atemp, hum, ...]
  * Values are not clear [Column season has values (1,2,3,4), which number represents which season?]
  * Some values are in binary values which not evryone understands [holiday, workingday]
  * We have some kind of repeated data [dteday -> (yr,mnth,weekday)], [workingday is the same as holiday]

These problems create clutter in the data and make it harder for us to understand it. In the first glimpse the data is difficult to read and extract estimates.
</p>
<br><br />

#### [TASK 1]
<p>
Our first task in our Data Wrangling for the file ("BikeWashingtonDC.csv") is to remove all some columns that are unwanted and create repeatition in our data. \

  * instant (unique number for each record)
  * yr (year)
  * mnth (month)
  * weekday (day of the week)
  * workingday (if the specific day was a holiday or not)
  * weathersit (weather condition)
  * atemp (normalized feeling temparature)
  * casual (number of bikes rented by casul users)
  * registered (number of bikes rented by registered users)
  
**Implemantation idea** \
Using function select() form tidyverse package and the notation '-' we can select all the columns we want to remove.
</p>
```{r}
## Columns in the file before removing
names(washington_Bikes)
## Calling self-declared function to undertake given task 
washington_Bikes <- washington_Bikes %>%
  deleteColumn( c("instant",
                  "yr",
                  "mnth",
                  "weekday",
                  "workingday",
                  "weathersit",
                  "atemp",
                  "casual",
                  "registered"))
## Columns in file after removing.
names(washington_Bikes)
```
<br><br />

#### [TASK 2]
<p>
Our second task is to rename the remaining to columns to match exactly as the seoul file. Making the columns names exactly the same will help with creating a combination of the two tables (join), so it has to be the same case aswell. \

 * 'dteday' to 'Date'
 * 'cnt' to 'Count'
 * 'hr' to 'Hour'
 * 'temp' to 'Temperature'
 * 'hum' to 'Humidity'
 * 'windspeed' to 'WindSpeed'
 * 'season' to 'Season'
 * 'holiday' to 'Holiday'
 
**Implemantation idea** \
Using function rename() form tidyverse package we can rename the already existing column names.
</p>
```{r}
## Header Names before Renaming
names(washington_Bikes)
washington_Bikes <- washington_Bikes %>%
  rename(Count = cnt, ## Using function we are renaming the columns.
         Temperature = temp, 
         WindSpeed = windspeed, 
         Season = season,
         Humidity = hum,
         Date = dteday,
         Hour = hr,
         Holiday = holiday)
## Header Names after Renaming
names(washington_Bikes)

```
<br><br />

#### [TASK 3]
<p>
Our third task is to convert the Humidity field's values to a percentage. At the moment the field Humidity in the two files are given two different measurements, we will have both in percentage after this task. \

 * Value is divided by 100 at the moment, so we will need to multiply it by 100 to get it to a % value.
  
**Implemantation idea** \
Using function mutate() from tidyverse package we can modify the existing columnn and its fields.
</p>
```{r}
## Printing first 6 rows to show the value now in decimal
head(washington_Bikes$Humidity)
washington_Bikes <- washington_Bikes %>%
  mutate(Humidity = Humidity * 100) ## multiply existing value with 100 to make a percentage value.
## Printing first 6 rows to show values out of a hundred (in %), smallest is 0 and largest 100.
head(washington_Bikes$Humidity)
```
<br><br />

#### [TASK 4]
<p>
Our fourth task is to convert the Temperature field's values to degree celsius At the moment the field Temperature in the two files are given two different measurements, we will have both in percentage after this task. Temperature in Washington file is normalized. \

 * Value is normalized which means formula $[(value -Tmin)/Tmax-Tmin]$ was applied on it. [Tmin = -8, Tmax = 39]
 * We have to reverse this fomrula which means we have to apply formula $[(value)*(Tmax-Tmin)+Tmin] $. [Tmin = -8, Tmax = 39]

**Implemantation idea** \
Using function mutate() from tidyverse package we can modify the existing columnn and its fields.
</p>
```{r}
## Printing first 6 rows to show the value are now normalized.
head(washington_Bikes$Temperature)

Tmin <- -8
Tmax <- 39
washington_Bikes <- washington_Bikes %>%
  mutate(Temperature = (Temperature)*(Tmax-Tmin)+Tmin) ## apply formula so we convert back to degree celsius.
## Printing first 6 rows to show values out of in degree celsius.
head(washington_Bikes$Temperature)
```
<br><br />

#### [TASK 5]
<p>
Our fifth task is to convert the WindSpeed field's values to m/s At the moment the field WindSpeed in the two files are given two different measurements, we will have both in percentage after this task. WindSpeed fieald in washinghton file is divided by 69km/s while in the Seoul file is in m/s \

  * First we need to conver WindSpeed to km/s, so we multiply by 69 because its divided by 69km/x
  * After we apply the given formula $"Wind (m/s) = 0.2777778 Ã— Wind (km/h)"$ formula was found found from [goodcalculator.com](https://goodcalculators.com/wind-speed-converter/)
  
**Implemantation idea** \
Using function mutate() from tidyverse package we can modify the existing columnn and its fields.
</p>
```{r}
## Printing first 6 rows to show the value are in (km/s)/69
head(washington_Bikes$WindSpeed)
makeToKM <- 69
multiplayerConstant <- 0.2777778
washington_Bikes <- washington_Bikes %>%
  mutate(WindSpeed = ((WindSpeed)*(makeToKM))*multiplayerConstant) ## apply formula so we convert back to degree m/s
## Printing first 6 rows to show values are now in m/s
head(washington_Bikes$WindSpeed)
```
<br><br />

#### [TASK 6]
<p>
Our sixth task is to change the values of field season. After convert the class to a factor and give the factor levels a specific order. \
 
 * '1' to 'Winter'
 * '2' to 'Spring'
 * '3' to 'Summer'
 * '4' to 'Autumn'
 
The order the levels must follow are:

 * Spring > Summer > Autumn > Winter 
 
**Implemantation idea** \
Using function mutate() form tidyverse package and ifelse conditional statement we will change the fields values. After by using the mutate() function from tidyverse we can change the class of the field  to a factor.
</p>
```{r}
## Printing the 6 fist rows to show factor values before changing
head(washington_Bikes$Season)
## Printing the class of Season to show its a 'integer'
class(washington_Bikes$Season)
washington_Bikes <- washington_Bikes %>%
  mutate(Season = ifelse(Season == 1, "Winter", Season)) %>% ## Changing values to the appropriate factors Winter | Summer | Autumn | Spring.
  mutate(Season = ifelse(Season == 2, "Spring", Season)) %>% 
  mutate(Season = ifelse(Season == 3, "Summer", Season)) %>% 
  mutate(Season = ifelse(Season == 4, "Autumn", Season)) %>% 
  mutate(Season = factor(Season, levels = c("Spring", "Summer", "Autumn", "Winter"))) ## Changing type to factor with seq order.
## Printing the 6 fist rows to show factor values have changed.
head(washington_Bikes$Season)
## Printing the class of Season to show its a 'factor'
class(washington_Bikes$Season)

```
<br><br />

#### [TASK 7]
<p>
Our seventh task is to convert the Holiday values to Yes or No. After we need to convert the type to  factor, so the data can be categorzied. \
  
  * 0 to 'No'
  * 1 to 'Yes'

**Implemantation idea** \
Using function mutate() form tidyverse package and ifelse conditional statement we will change the fields values. After by using the mutate() function from tidyverse we can change the class of the field  to a factor.
</p>
```{r}
## Printing the 6 fist rows to show factor values before changing
head(washington_Bikes$Holiday)
## Printing the class of Holiday to show its a 'character'
class(washington_Bikes$Holiday)
washington_Bikes <- washington_Bikes %>%
  mutate(Holiday = ifelse(Holiday == 0, "No", "Yes")) %>% ## Changing values to Yes & No (0=No, 1=Yes).
  mutate(Holiday = factor(Holiday, levels = c("Yes", "No"))) ## Changing type to factor with seq order.
## Printing the 6 fist rows to show factor values have changed.
head(washington_Bikes$Holiday)
## Printing the class of Holiday to show its a 'factor'
class(washington_Bikes$Holiday)
```
<br><br />

#### [TASK 8]
<p>
Our eight task is to convert the class of field Date from 'character' to 'Date'. \

**Implemantation idea** \
With the help of tidyverse function 'as_date()' we will change the type/class of the attribute to date.
</p>
```{r}
## Printing class of column Date before mutation.
class(washington_Bikes$Date)

washington_Bikes <- washington_Bikes %>%
  convertDate("ymd")

## Printing class of column Date after mutation.
class(washington_Bikes$Date)
```
<br><br />

#### [TASK 9]
<p>
Our ninth task is to add a new column with name 'FullDate' which will hold the Date and Hour of the day the bike was rented, in format 'Y-M-D H:M:S' \
**Implemantation idea** \
With help of package lubridate we have a function called 'make_datetime' which does this action for us in the format asked.
</p>
```{r}
## Printing column names to show that FullDate does not exist.
names(washington_Bikes)
## Calling a self-declared function to apply this task.
washington_Bikes <- washington_Bikes %>%
  createFullDate()

## Printing column names to show creation of FullDate.
names(washington_Bikes)
## Printing first 6 rows of FullDate to show the value is in correct format.
head(washington_Bikes$FullDate)
```
<br><br />
<p>
After applying all these methods on the data set, we managed to clean the data and bring it to a 'tidy' state. Now the data is easier to read and manipulate in plotting and statistical analysis. Additionally the data is now in the same state as Seoul file which will allow us to join/combile the data sets and explore different relationships
</p>
###### The result of Seoul, South Korea Data File after Data Wrangling is : 
```{r,}
head(washington_Bikes)
```
<br><br />

## DATA VISUALISATION :

#### Air temperature variation over the course of a year
<p>
We will apply some visualisation and statistical analysis to compare the air temperature of both locations. \
Due to my personal Laptop not being powerful enough i will be using only ggplot2 for the visualisation aspect rather than ggplotly. We will see both a point plot and boxplot for both different datasets.
</p>
```{r,fig.align='center', fig.height=8, fig.width=10}
## aligns the plot/figure in the center
## height/width gives size  in inches
ggplot(seoul_Bikes) +
  geom_point(aes(x = Date, y = Temperature), col="dark grey") +
  stat_smooth(aes(x = Date, y = Temperature)) + ## To see the distribution density
  xlab("Date") +  ## Naming x and y axes.
  ylab("Air Temperature (degrees celsius)") +
  ggtitle("Air Temperature variation of Seoul, Sount Korea") + ## Adding title to graph
  theme(plot.title = element_text(hjust = 0.5)) ## To align the title of the graph in the center, code fourd on stackoverflow :" https://stackoverflow.com/questions/40675778/center-plot-title-in-ggplot2 "
```
<p>
Using the point plot and a stat_smooth() we can view the Air Temperature's distribution density of how the air temperature varies in Seoul, South Korea. There is a variety of temperature's the warmest months are between may and august while the others get colder.
</p>
```{r}
## The mean average of air temperature.
seoul_Bikes %>% 
  summarise(Mean=mean(Temperature))
## The hottest day
seoul_Bikes %>% 
  summarise(Maximum=max(Temperature))
## The coldest day.
seoul_Bikes %>% 
  summarise(Minimume=min(Temperature))
```
<p>
It can reach very hot days up to nearly 40 degrees cesius, but it can also be very cold nearly -18 degrees celsius.
</p>

```{r,fig.align='center', fig.height=8, fig.width=10}
ggplot(washington_Bikes) +
  geom_point(aes(x = Date, y = Temperature), col = "orange") +
  stat_smooth(aes(x = Date, y = Temperature)) + 
  xlab("Date") + 
  ylab("Air Temperature (degrees celsius)") +
  ggtitle("Air Temperature variation of Washinghton,DC, America") +
  theme(plot.title = element_text(hjust = 0.5))
```
<p>
Utilizing the point plot and a stat_smooth() we can view the Air Temperature's distribution density of how the air temperature varies in Washinghton, DC. There is a similar density as Seoul. We can see the curve going up and back down two times. This is because the data in Washinghton's is over two years rather than one year in Seou's data.
</p>
```{r}
## The mean average of air temperature.
washington_Bikes %>% 
  summarise(Mean=mean(Temperature))
## The hottest day
washington_Bikes %>% 
  summarise(Maximum=max(Temperature))
## The coldest day.
washington_Bikes %>% 
  summarise(Minimume=min(Temperature))
```
<p>
The average temperature in Washinghton is higher than Seoul. Both locations hotest days are close. But Seoul winter is a lot colder than Washinghton. We can see a difference of 10 degrees celsius.
</p>

#### Do seasons affect the average number of rented bikes?
```{r,fig.align='center', fig.height=8, fig.width=8}
ggplot(seoul_Bikes) +
  geom_boxplot(aes(x = Season, y = Count), col = "dark grey") +
  xlab("Season") + 
  ylab("Number of bikes rented") +
  ggtitle("Bikes Rented per Season in Seoul, South Korea") +
  theme(plot.title = element_text(hjust = 0.5))
```
<p>
From the boxplot graph above we can observe there is a significant drop of bikes rented in the winter. The highest renting season is summer, although autumn and spring are not far behind. We can conclude that in Seoul, the bikes rented a day is depended on the season.
</p>

```{r, fig.align='center', fig.height=8, fig.width=8}
ggplot(washington_Bikes) +
  geom_boxplot(aes(x = Season, y = Count), col = "orange") +
  xlab("Season") + 
  ylab("Number of bikes rented") +
  ggtitle("Bikes Rented per Season in Washinghton, DC, America") +
  theme(plot.title = element_text(hjust = 0.5))
```
<p>
From the boxplot graph above we can observe there is a significant drop of bikes rented in the winter as well in Washington. The highest renting season is summer again, although autumn and spring are not far behind. We can conclude that for Washington, the bikes rented a day is depended on the season. \
Both locations are have a dramatic fall of rented bikes in the winter. We can conclude that the number of bikes of rented is depended on the season.
</p>

#### Do holidays increase or decrease the demand for rented bikes?
```{r,fig.align='center', fig.height=8, fig.width=10}
ggplot(seoul_Bikes) +
  geom_boxplot(aes(x = Holiday, y = Count), col = "dark grey") +
  xlab("Holiday") + 
  ylab("Number of bikes rented") +
  ggtitle("Bikes Rented per Holiday in Seoul, South Korea") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r,fig.align='center', fig.height=8, fig.width=10}
ggplot(washington_Bikes) +
  geom_boxplot(aes(x = Holiday, y = Count), col = "orange") +
  xlab("Holiday") + 
  ylab("Number of bikes rented") +
  ggtitle("Bikes Rented per Holiday in Washinghton DC, America") +
  theme(plot.title = element_text(hjust = 0.5))
```
<p>
By observing the two above boxplot graphs, we can sum up that more bikes are rented when there is not a holiday. There is a bigger difference of the number of bikes rented in the Seoul dataset. We can see that when its not a holiday there is big difference to the number of rented bikes. While in the America dataset, the difference is smaller. \
Maybe a variable that depends on holiday is that the residents need to work when there are no holidays. The way of trasnportation is by bike.

</p>

#### How does the time of day affect the demand for rented bikes?
```{r, fig.align='center', fig.height=8, fig.width=10}
grouped_seoul <- seoul_Bikes%>%
   group_by(Hour) %>% ##Grouping data in groups per hour.
   summarise(Average.Rented=mean(Count))  ## Finding average number of bikes rented per hour.

ggplot(grouped_seoul,aes(x = Hour, y = Average.Rented, fill = Hour)) +
  geom_bar(stat = "identity") +
  labs(colour = "Hour of Day") +
  xlab("Hour of Day") + 
  ylab("Number of bikes rented") +
  ggtitle("Average Bikes Rented per Hour in Seoul, South Korea") +
  theme(plot.title = element_text(hjust = 0.5))
```
<p>
Using the bar graph we can view on average how busy each hour is in Seou. The graph is plotted using the average number of bikes rented per day. There is a big drop between 4-5 o'clock in the morning. There is a significant rise at 8 o' clock in the morning but falls again. We can view the demand of bikes start rising slowly slowly from 10 o' clock in the morning and richest the peak busiest hour at 18 o'clock. After that the demand starts dropping again. \
Using the mean demand of rented bikes per hour, our conclusion is that the busiest hours of the day is 8 in the mornig and 17-19 in the afternoon. The busiest hour is at 18:00 afternoon. \
</p>
```{r,fig.align='center', fig.height=8, fig.width=10}
grouped_wash <- washington_Bikes%>%
   group_by(Hour) %>% ##Grouping data in groups per hour.
   summarise(Average.Rented=mean(Count))  ## Finding average number of bikes rented per hour.

ggplot(grouped_wash,aes(x = Hour, y = Average.Rented, fill = Hour)) +
  geom_bar(stat = "identity") +
  labs(colour = "Hour of Day") +
  xlab("Hour of Day") + 
  ylab("Number of bikes rented") +
  ggtitle("Average Bikes Rented per Hour in Washinghton Dc, America") +
  theme(plot.title = element_text(hjust = 0.5))


```
<p>
Using the bar graph we can view on average how busy each hour is Washington. The graph is plotted using the average number of bikes rented per day. There is a big drop between 3-5 o'clock in the morning. There is a significant rise at 8 o' clock in the morning but falls again. We can view the demand of bikes start rising slowly slowly from 10 o' clock in the morning and richest the peak busiest hour at 17 o'clock and 18 o'clock. After that the demand starts dropping again.\
Using the mean demand of rented bikes per hour, our conclusion is that the busiest hours of the day is 8 in the morning and 16-18 in the afternoon. The busiest hour is at 15:00 afternoon. \
There is a similarity in both locations of the demand distribution by hour. This might be because at 8-9 in the morning the popultaion starts work and 17-18 the population finishes from work. This could also be a reason that there is more demand on bikes when its not holiday, since the citizents need to go to work. \
</p>

#### Is there an association between bike demand and the three meteorological variables (air temperature, wind speed and humidity)? 
 \
 
#### Seoul, South Korea
```{r,fig.align='center', fig.height=10, fig.width=15}
ggplot(seoul_Bikes) +
  geom_point(aes(x = Humidity, y = Temperature, size = Count, color = WindSpeed )) +
  stat_smooth(aes(x = Humidity, y = Temperature)) + 
  xlab("Humidity") + 
  ylab("Temperature") +
  ggtitle("Bikes rented based on the 3 meteorological variables, Seoul") +
  theme(plot.title = element_text(hjust = 0.5))
```
<p>
The above point plot is using all three meteorological variables to examine if the demand of bikes rented is depended to them. The size of the point reveals the number of bikes rented. The larger the point the more bikes were rented. When Temperature goes over ten we can see the number of bikes rented has incresed. By the color of each point we can understand that as the Wind Speed grows higher then 4 m/s the number of rented bikes decreases. Additionally using the x and y axes it is noticed when Temperature and Humidity is low or high the number of rented bikes are less. We dont know if this observation is due to the combination of all variables, or just by one of the variable. Below we will review graphs for each meteorological attribute.
</p>
```{r,fig.align='center', fig.height=10, fig.width=15}
ggplot(seoul_Bikes) +
  geom_point(aes(x = Humidity, y = Count, size = Count) , col ="red") +
  stat_smooth(aes(x = Humidity, y = Count), method = "lm", col = "black") +
  stat_smooth(aes(x = Humidity, y = Count), col = "blue") +
  xlab("Humidity out of %") + 
  ylab("Number Rented Bikes") +
  ggtitle("Bikes rented based on Humidity") +
  theme(plot.title = element_text(hjust = 0.5))
```
<p>
The point plot above is showcasing the relationship between the number of bikes rented with the level of humidity. In the graph we have two lines that reveals the relationships.

 * Black line: Is a linear model which is telling us that as Humidity increases so does the number of rented bikes.
 * Blue line: Is a density distribution which is telling us that as humidity slowly increases so does the number of rented bikes, but when humidity starts going over 75% there drop in the number of bikes rented.
 
When Humidity is between (25-75)% that is when the number of bikes rented are high. Additionally between the (25-75)% interval we have more records of rented bikes. This indicates days with such humidity were busier.
</p>
```{r,fig.align='center', fig.height=10, fig.width=15}
ggplot(seoul_Bikes) +
  geom_point(aes(x = WindSpeed, y = Count, size = Count) , col ="green") +
  stat_smooth(aes(x = WindSpeed, y = Count), method = "lm", col = "black") +
  stat_smooth(aes(x = WindSpeed, y = Count), col = "blue") +
  xlab("WindSpeed m/s") + 
  ylab("Number Rented Bikes") +
  ggtitle("Bikes rented based on WindSpeed") +
  theme(plot.title = element_text(hjust = 0.5))
```
<p>
The point plot above is showcasing the relationship between the number of bikes rented with the level of wind speed In the graph we have two lines that reveals the relationships.

 * Black line: Is a linear model which is telling us that as wind speed increases the number of rented bike are decreasing.
 * Blue line: Is a density distribution which is telling us that as wind speed slowly slowly increases the number  bikes rented are increasing, but when the wind speed exceeds 4m/s there is a large dramatic fall to the number of bikes rented.
 
When wind speed is over 4m/s the number of bikes rented are limited. Records of rented bikes were limited also. The records are very few and influence the linear model. This is one of the reasons the linear model is on a rise.
</p>
```{r,fig.align='center', fig.height=10, fig.width=15}
ggplot(seoul_Bikes) +
  geom_point(aes(x = Temperature, y = Count, size = Count) , col ="orange") +
  stat_smooth(aes(x = Temperature, y = Count), method = "lm", col = "black") +
  stat_smooth(aes(x = Temperature, y = Count), col = "blue") +
  xlab("Temperature degrees Celsius") + 
  ylab("Number Rented Bikes") +
  ggtitle("Bikes rented based on Temperature") +
  theme(plot.title = element_text(hjust = 0.5))
```
<p>
The point plot above is showcasing the relationship between the number of bikes rented with the level of temperature In the graph we have two lines that reveals the relationships.

 * Black line: Is a linear model which is telling us that as Temperature becomes warmer the number of bikes rented are getting higher
 * Blue line: Is a density distribution which is telling us that as the Temperature is getting warmer the number of bikes rented are increasing, but when temperature goes over 30 degrees celsius the number of bikes rented are becoming less.
 
For very cold or hot Temperature's the number of rented bikes are less. When temperature is between 10-30 degrees celcius, the records of rented bikes double as do the nnumber of bikes rented.
</p>
<p>
From the above graphs we can accept that each meteorological variable affects the number of bikes rented. There is a big difference of number of bikes rented when the wind speed is very strong or when the temperature and humidity is very low or very high. \
When the temperature is between 0-20 degrees celsius, humidity is between 25-75 % and wind speed is under 4m/s, the number bikes rented are there highest.
</p>
 \
 
 #### Washington DC, America
```{r,fig.align='center', fig.height=10, fig.width=15}
ggplot(washington_Bikes) +
  geom_point(aes(x = Humidity, y = Temperature, size = Count, color = WindSpeed )) +
  stat_smooth(aes(x = Humidity, y = Temperature)) + 
  xlab("Humidity") + 
  ylab("Temperature") +
  ggtitle("Bikes rented based on the 3 meteorological variables, Washington DC") +
  theme(plot.title = element_text(hjust = 0.5))
```
<p>
The above point plot is using all three meteorological variables to examine if the demand of bikes rented is depended to them. The size of the point reveals the number of bikes rented. The larger the point the more bikes were rented. When Temperature goes over ten we can see the number of bikes rented have a small increase, not as big as in Seoul. By the color of each point we can understand that as the Wind Speed grows higher then 8-12 m/s the number of rented bikes decreases. The wind speed in America is more powerful. When the wind speed is at 4m/s the number of rented bikes are still high. Additionally using the x we can observe when Humidity is low there are limited records of rented bikes and the number of bikes rented is small. From the y axes we can see the relationship between the temperature and the number of rented bikes. Records of rented bikes are approximately the same between all the temperature values, but when temperature goes over 10 degrees celcius we can see the size of the points grow. This is to detail that the number of bikes rented are higher. We don't know if this observation is due to the combination of all variables, or just by one of the variable. Below we will review graphs for each meteorological attribute.
</p>
```{r,fig.align='center', fig.height=10, fig.width=15}
ggplot(washington_Bikes) +
  geom_point(aes(x = Humidity, y = Count, size = Count) , col ="red") +
  stat_smooth(aes(x = Humidity, y = Count), method = "lm", col = "black") +
  stat_smooth(aes(x = Humidity, y = Count), col = "blue") +
  xlab("Humidity out of %") + 
  ylab("Number Rented Bikes") +
  ggtitle("Bikes rented based on Humidity") +
  theme(plot.title = element_text(hjust = 0.5))
```
<p>
The point plot above is showcasing the relationship between the number of bikes rented with the level of humidity. In the graph we have two lines that reveals the relationships.

 * Black line: Is a linear model which is telling us that as Humidity increases the number of bikes rented decreases. 
 * Blue line: Is a density distribution which is telling us that as humidity slowly increases so does the number of rented bikes, but when humidity reaches 25 % the records and rented bikes start decreasing.
 
When Humidity is between (0-25)% there as significant increase of rented bikes. But after 25% Humidity the records and number of bikes rented decrease in a very slow.
</p>
```{r,fig.align='center', fig.height=10, fig.width=15}
ggplot(washington_Bikes) +
  geom_point(aes(x = WindSpeed, y = Count, size = Count) , col ="green") +
  stat_smooth(aes(x = WindSpeed, y = Count), method = "lm", col = "black") +
  stat_smooth(aes(x = WindSpeed, y = Count), col = "blue") +
  xlab("WindSpeed m/s") + 
  ylab("Number Rented Bikes") +
  ggtitle("Bikes rented based on WindSpeed") +
  theme(plot.title = element_text(hjust = 0.5))
```
<p>
The point plot above is showcasing the relationship between the number of bikes rented with the level of wind speed In the graph we have two lines that reveals the relationships.

 * Black line: Is a linear model which is telling us that as wind speed increases the number of rented bike are increase
 * Blue line: Is a density distribution which is telling us that as wind speed slowly slowly increases the number  bikes rented are increasing, but when the wind speed exceeds 5-6m/s there is a change on the slope and the number of rented bikes start decreasing slowly.
 
There is not a significant difference to the number of rented bikes after the 4m/s interval like Seoul. When wind speed exceeds 10 m/s thats when there is a big decrease in bike demand in america.
</p>
```{r,fig.align='center', fig.height=10, fig.width=15}
ggplot(washington_Bikes) +
  geom_point(aes(x = Temperature, y = Count, size = Count) , col ="orange") +
  stat_smooth(aes(x = Temperature, y = Count), method = "lm", col = "black") +
  stat_smooth(aes(x = Temperature, y = Count), col = "blue") +
  xlab("Temperature degrees Celsius") + 
  ylab("Number Rented Bikes") +
  ggtitle("Bikes rented based on Temperature") +
  theme(plot.title = element_text(hjust = 0.5))
```
<p>
The point plot above is showcasing the relationship between the number of bikes rented with the level of temperature In the graph we have two lines that reveals the relationships.

 * Black line: Is a linear model which is telling us that as Temperature becomes warmer the number of bikes rented are getting higher
 * Blue line: Is a density distribution which is telling us that as the Temperature is getting warmer the number of bikes rented are increasing, but when temperature goes over 30 degrees celsius the number of bikes rented start decreasing.
 
As temperature becomes warmer, the records and the number of rented bikes increase. When the temperature reaches 30 degrees celcius the slope changes direction and we can observe the number of rented bikes the number of records are becoming less. The coldest Temperature in Washington is approximately -7 degrees celsius while in Seoul is -17 degrees celsius. In Washington even if its cold bikes are still getting rented, on the other hand in Seoul cold temperature the number of bikes rented are limited.
</p>
<p>
From the above graphs we can accept that each meteorological variable affects the number of bikes rented. There is a big difference of number of bikes rented when the wind speed is very strong or when the humidity is very low. As temperature increases so does the number of bikes rented. There isn't a big fall of bikes rented when considering Temperature for Washington. In the Seoul dataset Temperature was a big influence to the number of bikes rented. \
In Washington the busiest weather conditions are Temperature is between 20-30 degrees celsius, wind speed is between 3-6 m/s and Humidity is between 25-75%.
</p>
 \

## STATISTICAL ANALYSIS :

#### Linear Modelling Fitting

#### Seoul, South Korea
```{r}
linear_model_log_seoul <- lm(log(Count) ~ Season + Humidity + Temperature + WindSpeed,
                             data = seoul_Bikes)
summary(linear_model_log_seoul)
```
<p>
The summary gives us some explanation of the data and the influence of each variable has on the variable Count (Number of rented bikes). 
 * Estimation column indicates the gradient value. If the gradient is positive, this means as response variable value increases when the explanatory variable increases. If the gradient is negative this means as the explanatory variable increases that the response variable decreases.
 * From the above point, we can observe that as Wind Speed, Temperature increases so does the number of rented bikes. While Humidity increases the number of rented bikes decreases.
 * Season "Spring" does not appear in the summary because it is a categorized variable. "Winter", "Autumn" and "Summer" are estimations from the "Spring" Value. Resulting to "Summer" having a gradient -0.0036038 from "Spring". 
 * Our R-Squared value is approximately 0.5 that represents the dependency of each explanatory variable with the response. This means that 50% of the independent variables is  explains the response variable. This shows our variables are independent from each other. A value of 0.5 is not high but also not low, its a medium effect on each other.
 * From the Pr(>|t|) we can see the variables that make the most influence on the outcome, for this data Temperature, Humidity and Season are a big influence on the outcome of the data.
</p>

#### Washinghton DC, America
```{r}
linear_model_log_wash <- lm(log(Count) ~ Season + Humidity + Temperature + WindSpeed, 
                            data = washington_Bikes)
summary(linear_model_log_wash)
```
<p>
Now we will explain the summary data for Washington DC data.
 * From the above point, we can observe that as Wind Speed, Temperature increases so does the number of rented bikes. While Humidity increases the number of rented bikes decreases.
 * Season "Spring" does not appear in the summary because it is a categorized variable. "Winter", "Autumn" and "Summer" are estimations from the "Spring" Value. Resulting to "Summer" having a gradient -0.3651680 from "Spring". 
  * Our R-Squared value is approximately 0.3 that represents the dependency of each explanatory variable with the response. This means that 30% of the independent variables is  explains the response variable. This shows our variables are independent from each other. A value of 0.3 is low measure, this means a lot of data are away from the slope.
 * From the Pr(>|t|) we can see the variables that make the most influence on the outcome, for this data Wind Speed is the biggest influence on the outcome of the data.
</p>
<p>
We can see that in Seoul Wind Speed was not the biggest influence to the response variable while for Washington it is. Additionally winter in America is a lot busier and the number of rented bikes don't differ a lot from other seasons as they do in Seoul. \
In both situations our R-Squared value is not high but low and medium. \
</p>


#### Confident Intervals on Linear Model 
<p>
We will examine the confidence interval of the data at 97%. \
Our confidence intervals of 97% does not mean that future values will fall in between the lower and upper limit. It means that if we run 100 random tests 97 of the results will fall in the interval between lower and upper limit and 3 won't. \
</p>

###### Seoul, South Korea.
```{r, message=FALSE, fig.align='center', fig.height=8}
confint(linear_model_log_seoul, level = 0.97)
```

###### Washinghton DC, America.
```{r, message=FALSE, fig.align='center', fig.height=8}
confint(linear_model_log_wash, level = 0.97)
```
<p>
The confidence intervals are not the most reliable source in my opinion for the given situation. The reason is because we are dealing with variables controlled by weather. We cannot predict with little uncertainty what our weather conditions will be tomorrow or in a year. The weather changes really fast and is unpredictable. For this reason even we simulate such process we cannot know with 97% certainty the values will actually fall in those intervals. Our population parameters might look the same as our samples parameters but might also look very different due to the reason our conditions might actually be very different.
</p>

#### Predictions According to Linear Model on Seoul, South Korea.
<p>
We will use our linear model to predict future numbers. We first need to create the data we want our future data to represent. We will create a data.frame called predictData holding and representing the future values. We will use the predict() function to predict future data. For the interval argument will be using the value "prediction", this is because we are doing a prediction to get obtain values that are uncertain. We cannot predict future values with certainty since we don't know what might happen. A prediction interval widens the difference between the lower and upper value that the future data will fall in. In my opinion is a safer option because you plan for the worst. Using a confidence interval would have smaller ranges and it is more likely in the future the values wont fall in the interval computed. \ 
Additionally our R-Squared value is low, this means that our explanatory variables do not explain our response variable  at the level we want. Since is under 0.7, our linear model is not very good.
</p>
```{r, message=FALSE, fig.align='center', fig.height=8}
## Need to create the data that we want our prediction to be based on 
predictData <- data.frame(Season = "Winter", ##Assigning the data we want to make a prediction on.
                          Temperature = 0.0,
                          Humidity = 20.0,
                          WindSpeed = 0.5)

predict(linear_model_log_seoul, ##Creating the prediction based on the linear model. With level 90%
        newdata = predictData,
        level = 0.90,
        interval = "prediction") ## Using "prediction" instead of "confidence" to have wider ranges since we are predicting data from random experiments.
```
<p>
After applying the prediction we can see the mean is 5.913404 and the values will range from 4.5512 to 7.275607 for variable Count when Season will be "Winter", Temperature will be 0 degrees celsius, Humidity will be up to 20% and Wind Speed will be 0.5 m/s
</p>
#### Predictions According to Linear Model Washinghton DC, America.
```{r, message=FALSE, fig.align='center', fig.height=8}
predict(linear_model_log_wash,
        newdata = predictData,
        level = 0.90,
        interval = "prediction")
```
<p>
After applying the prediction we can see the mean is 4.276058 and the values will range from 2.19759 to 6.354526 for variable Count when Season will be "Winter", Temperature will be 0 degrees celsius, Humidity will be up to 20% and Wind Speed will be 0.5 m/s
</p>

<p>
We have reached the end of the project. I will append in the end, a section called Appendix which will hold code of my self-created functions to undertake some of the processes in the Data Wrangling.
</p>

## APPENDIX 

```{r, include=TRUE}
## Functions that will be used in the program multiple times.
## For deleting unwanted columns.
deleteColumn <- function(dataFrame, columns){
  for (col in columns){
    dataFrame <- dataFrame %>%
      select(-col) ## '-' notation means to select all except the given column.
  }
  return(dataFrame)
}

## For converting a column to class Date.
## formatDate is used because for the conversion you need to specify in what format your date is in.
## Using functions that tidyverse and lubridate offer.
convertDate <- function(dataFrame, formatDate){
  dataFrame <- dataFrame %>%
    mutate(Date = (as_date(parse_date_time(Date,formatDate)))) 
  return(dataFrame)
}

## For Creating new Column FullDate holding Date and Hour of the day.
## as.integer(format(Date, format="%Y") -> this command is needed to extract the correct number/attribute from column Date. "%Y" tells the function to extract the year. as.integer() converts the character into an integer becasue field year expects as integer number. All work the same [month, day, hour]
createFullDate <- function(dataFrame){
  dataFrame <- dataFrame %>%
  mutate(FullDate = make_datetime( year = as.integer(format(Date, format="%Y"))
                                  , month = as.integer(format(Date, format="%m"))
                                  ,day = as.integer(format(Date, format="%d"))
                                  , hour = Hour 
                                  ,min = 0
                                  , sec = 0 ))
  return(dataFrame)
  
}

```


